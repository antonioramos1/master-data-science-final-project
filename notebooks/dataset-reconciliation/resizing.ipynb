{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing images\n",
    "\n",
    "In order to make the dataset more manageable we size down the images to width 300 and preserving the original aspect ratio, we will also create a csv file to record the resizing factor applied to each customer photo so we can updated the bounding boxes coordinates.\n",
    "\n",
    "Resizing customer images to width 300 is likely to have a bigger impact on small items such as belts or bags, however for the purpose of this project our scope is large items such as dresses and tops and we assume that a better quality set of images would be provided in order to make it scalable to more clothing categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  #disables .loc assignment warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating customer and retrieval dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files are separated into 3 classes: retrieval, train and test. Each of these classes have a json for each of the 11 clothing categories.  The function below merges all categories json files under the 3 classes, then train and test are also merged so we can do a custom data split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_labels(path_labels, store_images=False):\n",
    "    \"\"\"formats original jsons into either retrival set or customer set\"\"\"\n",
    "    \n",
    "    json_files = os.listdir(path_labels)\n",
    "    json_files = [os.path.join(path_labels, file) for file in json_files] #reading in all json files\n",
    "    if store_images==False:\n",
    "        all_files = [file for file in json_files if \"retrieval\" in file]\n",
    "    else:\n",
    "        all_files = [file for file in json_files if (\"train\" in file) | (\"test\" in file)]\n",
    "    \n",
    "    files_df = pd.DataFrame() #appending all retrieval / customer into a dataframe\n",
    "    for file in all_files:\n",
    "        files_df = files_df.append(pd.read_json(file))\n",
    "    \n",
    "    category_files = [file.split(\"_\")[-1].split(\".json\")[0] for file in all_files] #finding category file\n",
    "    category_nrows = [pd.read_json(file).shape[0] for file in all_files] #finding number of rows for each file\n",
    "    \n",
    "    files_df[\"category\"] = \"\"\n",
    "    for n, category in enumerate(category_files):\n",
    "        if n == 0:\n",
    "            files_df[\"category\"].iloc[0:category_nrows[0]] = category\n",
    "        index_0 = sum(category_nrows[:n])\n",
    "        index_1 = sum(category_nrows[:n+1])\n",
    "        files_df[\"category\"].iloc[index_0:index_1] = category\n",
    "    files_df = files_df.reset_index(drop=True)\n",
    "    \n",
    "    files_df[\"id\"] = files_df[\"product\"].astype(str) + \"_\" + files_df[\"category\"] #creating key for pair matching\n",
    "\n",
    "    if store_images == True: #fixing format of bboxes, originally a dictionary within a column\n",
    "        files_df[\"bbox\"] = files_df[\"bbox\"].apply(lambda x: {k:v for k, v in sorted(x.items())}) #fixes missalignment in label order\n",
    "        files_df[\"bbox\"] = files_df[\"bbox\"].apply(lambda x: \"\".join(map(lambda x: str(x) + \",\", list(x.values()))))\n",
    "\n",
    "        bboxes = files_df[\"bbox\"].str.split(\",\",expand=True).drop(columns=[4])\n",
    "        bboxes.columns=([\"height\", \"left\", \"top\", \"width\"])\n",
    "        files_df = pd.concat([files_df,bboxes], axis=1).drop(columns=[\"bbox\"])\n",
    "        return files_df\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels = \"../../labels\"\n",
    "customer_df = format_labels(path_labels, store_images=True)\n",
    "retrieval_df = format_labels(path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_list = customer_df[\"photo\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing photos\n",
    "~ 5h runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(dataset_path, output_path, customer_list, width=300):\n",
    "    \"\"\"Resizing fixed to width 300 and same aspect ratio due to having high variability in current img size.\n",
    "    aspect_ratios.csv file is created to updated the bounding boxes coordinates for customer photos on a later notebook\"\"\"\n",
    "    \n",
    "    aspect_ratio = pd.DataFrame()\n",
    "    all_paths = os.listdir(dataset_path)\n",
    "    \n",
    "    for n, img_ in enumerate(tqdm(all_paths)):\n",
    "        try:\n",
    "            img_path = os.path.join(dataset_path, img_)\n",
    "            img_object = Image.open(img_path)\n",
    "            img_object = img_object.convert(\"RGB\") #exception with transparent channel, see https://stackoverflow.com/questions/48248405/cannot-write-mode-rgba-as-jpeg\n",
    "            if int(img_.split(\".\")[0]) in customer_list: #checking if image from customer and resizing\n",
    "                width_percent = (width/float(img_object.size[0]))\n",
    "                height_size = int((float(img_object.size[1])*float(width_percent)))\n",
    "                img_object = img_object.resize((width,height_size), Image.ANTIALIAS)\n",
    "                aspect_ratio = aspect_ratio.append({\"ratio\": width_percent, \"img\": img_}, ignore_index=True)\n",
    "            output_img = os.path.join(output_path, img_)\n",
    "            img_object.save(output_img)\n",
    "\n",
    "        except OSError: #corrupted images will break it\n",
    "            aspect_ratio = aspect_ratio.append({\"ratio\": \"corrupted\", \"img\": img_}, ignore_index=True)\n",
    "            pass\n",
    "    aspect_ratio.to_csv(\"../aspect_ratios.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159b85e033da4bed962e798429360bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=383169), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heret\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:2514: DecompressionBombWarning: Image size (99272481 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "C:\\Users\\heret\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:2514: DecompressionBombWarning: Image size (109820000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n",
      "C:\\Users\\heret\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:2514: DecompressionBombWarning: Image size (123871510 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 1h 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "image_resize(\"../../photos\", \"../../photos_resized\", customer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aspect_ratio.csv file will be used on the notebook 01-data-wrangling to update the bounding boxes coordinates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
